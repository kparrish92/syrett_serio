---
title: "Experiment 2"
output: html_document
date: "2024-11-3"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(here)
library(tidyverse)
library(bayestestR)
library(brms)
# load plotting function
source(here::here("report", "exp2", "pairwise_comp_function.R"))
# load model
exp2_mod = read_rds(here("data", "models", "exp2_model.rds"))
senses_tidy = read.csv(here("data", "tidy", "senses_tidy.csv")) 
data_for_priors = read.csv(here("data", "tidy", "prior_data.csv"))
```


### Our priors expressed as probabilities 

Priors were calculated on the basis of the data from experiment 1.
The ratings were used to predict answer of "is", "is not" or "both".
In particular, the data was conditionally mutated depending upon whether it came from the nonmember_tidy or member_tidy data set. For the nonmember data, ratings of 1 or 2 were predicted to be “is” answers, 3, 4 and 5 were “both” answers, and 6 and 7 were “is not” answers. On the other hand, the member_tidy predicted answers were essentially the opposite: 1 and 2 were predicted to be “is not” answers, 3, 4, 5 and were “both” answers, and 6 and 7 were “is” answers. 
The total proportion of predicted answers for each type was then divided by the total number of responses in a category to get the predicted probability.
For example, if, within Natural Kinds and member data, there were 5 answers, 1, 2, 5, 6, 7, then the predicted probability of "Is not" would be .4, "Both" would be .2, and "Is" would be .4. 
The ranges were chosen from setting a semi-conservative standard deviation in log-odds of .5.

```{r}
data_for_priors %>%
  filter(CategoryType == "Abstract" | CategoryType == "Artifact" | CategoryType == "Natural") %>% 
  mutate(log_odds = qlogis(predicted_grp)) %>% 
  mutate(upper = log_odds + .5) %>% 
  mutate(lower = log_odds - .5) %>% 
  mutate(upper_p = plogis(upper)) %>% 
  mutate(lower_p = plogis(lower)) %>% 
  mutate(predicted_grp_prob = round(predicted_grp, digits = 2)) %>% 
  mutate(predicted_upper_p = round(upper_p, digits = 2)) %>% 
  mutate(predicted_lower_p = round(lower_p, digits = 2)) %>% 
  mutate(Prior_range = paste0(predicted_grp_prob, " [", predicted_lower_p, "-", predicted_upper_p, "]" )) %>% 
  select(Prior_range, CategoryType, predicted_answer) %>% 
  pivot_wider(names_from = predicted_answer, values_from = Prior_range) %>% 
  knitr::kable(format = "pandoc")
```

### The results of the model

Model structure: `brm(Selection ~ CategoryType + (CategoryType | Participant)` 

`Selection` had three levels: "Both","Is not", and "Is". The model predicted the log-odds of each choice as a function of `CategoryType`.

`CategoryType` had three levels: "Natural", "Value" and "Artifact".

`Participant`: There were 48 participants, each with 18 data points total (6 per `CategoryType`). the model included a random slope of category type per participant. This both takes into account the nested structure of the data and allows for the estimation of individual probabilities per `CategoryType`. 


The table below reports the fixed effects and intercepts, as well as convergence metrics. This should be reported, but we won't use this to make inferences directly.

```{r}
describe_posterior(exp2_mod) %>% 
  as_tibble() %>% 
  select(-c("CI", "ROPE_CI", "ROPE_low", "ROPE_high")) %>% 
  mutate(Parameter = case_when(
    Parameter == "b_muIs_Intercept" ~ "Intercept 'is'", 
    Parameter == "b_muIsnot_Intercept" ~ "Intercept 'is not'", 
    Parameter == "b_muIs_CategoryTypeArtifact" ~ "Is_CategoryTypeArtifact", 
    Parameter == "b_muIs_CategoryTypeNatural" ~ "Is_CategoryTypeNatural", 
    Parameter == "b_muIsnot_CategoryTypeArtifact" ~ "Isnot_CategoryTypeArtifact",
    Parameter == "b_muIsnot_CategoryTypeNatural" ~ "Isnot_CategoryTypeNatural"
  )) %>% 
  mutate(ESS = round(ESS)) %>% 
  knitr::kable(format = "pandoc", digits = 2)

```

## The conditional effects based on the model 

This plot and table were generated from the model using the `conditional_effects` function in R. The function just does the addition needed and conversion to probability as a convenience. 

```{r}
conditional_effects(exp2_mod, categorical = TRUE)
```

```{r}
conditional_effects(exp2_mod, categorical = TRUE)[["CategoryType:cats__"]] %>% 
  select(effect1__, effect2__, estimate__, lower__, upper__) %>% 
  mutate(estimate__ = round(estimate__, digits = 2)) %>% 
  mutate(lower__ = round(lower__, digits = 2)) %>% 
  mutate(upper__ = round(upper__, digits = 2)) %>% 
  mutate(model_effect = paste0(estimate__, " [", lower__, " - ", upper__, "]")) %>% 
  rename("CategoryType" = "effect1__") %>% 
  select(CategoryType, effect2__, model_effect) %>% 
  pivot_wider(names_from = effect2__, values_from = model_effect) %>% 
  knitr::kable(format = "pandoc", digits = 2)
```

# The pairwise comparisons 

The pairwise comparisons are also based on the model. For any given comparison, we extract the 4000 iterations from the model for each and subtract them. This gives us a plausible range of effect sizes. If the distribution of estimate is around 0, then this would be evidence for the lack of an effect (with a particular probability measured by the proportion that falls within the ROPE).


Here is just one example:

```{r}
create_pairwise_plot("Is", "Value",
                     "Both", "Value", rope = .2)
```

We have a lot of possible comparisons: 81 in principle, but it's more like 36 that we really care about. Here is a very busy visualization of what I mean:

**Old plot**
```{r}
knitr::include_graphics(here("report", "exp2", "figs", "big_pairwise_plot.png"))
```

**Collapsed plots**
```{r}
knitr::include_graphics(here("report", "exp2", "figs", "ba_coll.png"))
```


We can decide together which specific differences are important to visualize. Here is a full table of the comparisons. Note that we can change the ROPE as it seems appropriate. 

```{r}
read.csv(here("data", "tidy", "pairwise_table.csv")) %>% 
   knitr::kable(format = "pandoc", digits = 2)
```


# Sensitivity analysis 

This will come at a later time - initially, it does not seem that the default priors qualitatively change the results. 